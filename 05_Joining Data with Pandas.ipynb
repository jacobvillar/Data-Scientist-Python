{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea4b97f2",
   "metadata": {},
   "source": [
    "# 1. Data Merging Basics\n",
    "\n",
    "    Tables = DataFrames\n",
    "    Merging = Joining \n",
    "    \n",
    "        OFFICE DATASET\n",
    "    \n",
    "            wards = pd.read_csv(\"Ward_Offices.csv\")\n",
    "            print(wards.head())\n",
    "            print(wards.shape())\n",
    "        \n",
    "        CENSUS \n",
    "        \n",
    "            census = pd.read_csv(\"Ward_Census.csv\")\n",
    "            print(wards.head())\n",
    "            print(wards.shape())\n",
    "            \n",
    "         RELATED BY WARD COLUMN \n",
    "         \n",
    "             wards_census = wards.merge(census, on = \"ward\"\n",
    "             print(wards_census.head())\n",
    "             print(wards_census.shape)\n",
    "             \n",
    "         SUFFIXES \n",
    "         \n",
    "         You may have noticed that the merged table has columns with suffixes of underscore x or y. This is because both the wards and census tables contained address and zip columns. To avoid multiple columns with the same name, they are automatically given a suffix by the merge method.\n",
    "         \n",
    "             wards_census = wards.merge(census, on = \"ward\", suffixes = ('_ward', '_cen'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8812ef",
   "metadata": {},
   "source": [
    "### 1.1 Inner Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e3f7065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n# Merge the taxi_owners and taxi_veh tables setting a suffix\\ntaxi_own_veh = taxi_owners.merge(taxi_veh, on='vid', suffixes=('_own','_veh'))\\n\\n# Print the value_counts to find the most popular fuel_type\\nprint(taxi_own_veh['fuel_type'].value_counts())\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "# Merge the taxi_owners and taxi_veh tables setting a suffix\n",
    "taxi_own_veh = taxi_owners.merge(taxi_veh, on='vid', suffixes=('_own','_veh'))\n",
    "\n",
    "# Print the value_counts to find the most popular fuel_type\n",
    "print(taxi_own_veh['fuel_type'].value_counts())\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bdfc91",
   "metadata": {},
   "source": [
    "Most common fuel type for taxis in Chicago are hybrids."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2278b91",
   "metadata": {},
   "source": [
    "#### 1.2.1 Inner joins and number of rows returned\n",
    "\n",
    "In step 1, the .merge() returned a table with the same number of rows as the original wards table. However, in steps 2 and 3, using the altered tables with the altered first row of the ward column, the number of returned rows was fewer. There was not a matching value in the ward column of the other table. Remember that .merge() only returns rows where the values match in both tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a92a9fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Print the first few rows of the census_altered table to view the change \\nprint(census_altered[[\\'ward\\']].head())\\n\\n# Merge the wards and census_altered tables on the ward column\\nwards_census_altered = wards.merge(census_altered, on = \"ward\")\\n\\n# Print the shape of wards_census_altered\\nprint(\\'wards_census_altered table shape:\\', wards_census_altered.shape)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Print the first few rows of the census_altered table to view the change \n",
    "print(census_altered[['ward']].head())\n",
    "\n",
    "# Merge the wards and census_altered tables on the ward column\n",
    "wards_census_altered = wards.merge(census_altered, on = \"ward\")\n",
    "\n",
    "# Print the shape of wards_census_altered\n",
    "print('wards_census_altered table shape:', wards_census_altered.shape)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b8ff48",
   "metadata": {},
   "source": [
    "## 1.2 One-to-many relationships\n",
    "\n",
    "One-To-One = Every row in the left table is related to only one row in the right table\n",
    "One-To-many = Every row in the left table is related to one or mores row in the right table  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bca1790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Merge the licenses and biz_owners table on account\\nlicenses_owners = licenses.merge(biz_owners, on='account')\\n\\n# Group the results by title then count the number of accounts\\ncounted_df = licenses_owners.groupby('title').agg({'account':'count'})\\n\\n# Sort the counted_df in desending order\\nsorted_df = counted_df.sort_values(by='account', ascending=False)\\n\\n# Use .head() method to print the first few rows of sorted_df\\nprint(sorted_df.head())\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Merge the licenses and biz_owners table on account\n",
    "licenses_owners = licenses.merge(biz_owners, on='account')\n",
    "\n",
    "# Group the results by title then count the number of accounts\n",
    "counted_df = licenses_owners.groupby('title').agg({'account':'count'})\n",
    "\n",
    "# Sort the counted_df in desending order\n",
    "sorted_df = counted_df.sort_values(by='account', ascending=False)\n",
    "\n",
    "# Use .head() method to print the first few rows of sorted_df\n",
    "print(sorted_df.head())'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9c98a1",
   "metadata": {},
   "source": [
    " After merging the tables together, you counted the number of repeated rows with the combination of .groupby() and .agg() statements. You see that president, followed by secretary, are the most common business owner titles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3a0e34",
   "metadata": {},
   "source": [
    "## 1.3 Merging multiple DataFrames\n",
    "\n",
    "    grants = pd.read_csv('Small_Business_Grant_Agreements.csv')\n",
    "    print(grants.head())\n",
    "    \n",
    "    Single Merge \n",
    "    \n",
    "        grants.merge(licences, on = [\"address\", \"zip\"]) \n",
    "    \n",
    "    Merging multiple tables\n",
    "    \n",
    "        grants_licenes_ward = grants.merge(licences, on = [\"address\", \"zip\"]) \\ \n",
    "                              .merge(wards, on = \"ward\", suffixes = ('_bus', '_ward'))\n",
    "                              \n",
    "        grants_licenses_ward.head()\n",
    "        \n",
    "    Merge three or more tables\n",
    "    \n",
    "        df1.merge(df2, on = \"col\") \\ \n",
    "            .merge(df3, on = \"col\")\n",
    "                                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee10dc3",
   "metadata": {},
   "source": [
    "#### 1.3.1 Total riders in a month\n",
    "\n",
    "Your goal is to find the total number of rides provided to passengers passing through the Wilson station (station_name == 'Wilson') when riding Chicago's public transportation system on weekdays (day_type == 'Weekday') in July (month == 7). Luckily, Chicago provides this detailed data, but it is in three different tables. You will work on merging these tables together to answer the question. This data is different from the business related data you have seen so far, but all the information you need to answer the question is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4248e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Merge the ridership, cal, and stations tables\\nridership_cal_stations = ridership.merge(cal, on=[\\'year\\',\\'month\\',\\'day\\']) \\t\\t\\t\\t\\t\\t\\t.merge(stations, on=\\'station_id\\')\\n\\n# Create a filter to filter ridership_cal_stations\\nfilter_criteria = ((ridership_cal_stations[\\'month\\'] == 7) \\n                   & (ridership_cal_stations[\\'day_type\\'] == \"Weekday\") \\n                   & (ridership_cal_stations[\\'station_name\\'] == \"Wilson\"))\\n\\n# Use .loc and the filter to select for rides\\nprint(ridership_cal_stations.loc[filter_criteria, \\'rides\\'].sum())'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Merge the ridership, cal, and stations tables\n",
    "ridership_cal_stations = ridership.merge(cal, on=['year','month','day']) \\\n",
    "\t\t\t\t\t\t\t.merge(stations, on='station_id')\n",
    "\n",
    "# Create a filter to filter ridership_cal_stations\n",
    "filter_criteria = ((ridership_cal_stations['month'] == 7) \n",
    "                   & (ridership_cal_stations['day_type'] == \"Weekday\") \n",
    "                   & (ridership_cal_stations['station_name'] == \"Wilson\"))\n",
    "\n",
    "# Use .loc and the filter to select for rides\n",
    "print(ridership_cal_stations.loc[filter_criteria, 'rides'].sum())'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ce83b1",
   "metadata": {},
   "source": [
    "Wilson station had 140,005 riders during weekdays in July."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cbf2ec",
   "metadata": {},
   "source": [
    "#### 1.3.2 Three table merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70ddd7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Merge licenses and zip_demo, on zip; and merge the wards on ward\\nlicenses_zip_ward = licenses.merge(zip_demo, on = \"zip\")            \\t\\t\\t.merge(wards, on = \"ward\")\\n\\n# Print the results by alderman and show median income\\nprint(licenses_zip_ward.groupby(\"alderman\").agg({\\'income\\':\\'median\\'}))'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Merge licenses and zip_demo, on zip; and merge the wards on ward\n",
    "licenses_zip_ward = licenses.merge(zip_demo, on = \"zip\")\\\n",
    "            \t\t\t.merge(wards, on = \"ward\")\n",
    "\n",
    "# Print the results by alderman and show median income\n",
    "print(licenses_zip_ward.groupby(\"alderman\").agg({'income':'median'}))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983fac46",
   "metadata": {},
   "source": [
    "#### 1.3.3 One-to-many merge with multiple tables\n",
    "\n",
    "You will need to merge three tables to help you choose your location. The land_use table has info on the percentage of vacant land by city ward. The census table has population by ward, and the licenses table lists businesses by ward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67469016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Merge land_use and census and merge result with licenses including suffixes\\nland_cen_lic = land_use.merge(census, on=\\'ward\\')                     .merge(licenses, on=\\'ward\\', suffixes=(\\'_cen\\',\\'_lic\\'))\\n\\n# Group by ward, pop_2010, and vacant, then count the # of accounts\\npop_vac_lic = land_cen_lic.groupby([\\'ward\\',\\'pop_2010\\',\\'vacant\\'], \\n                                   as_index=False).agg({\\'account\\':\\'count\\'})\\n\\n# Sort pop_vac_lic and print the results\\nsorted_pop_vac_lic = pop_vac_lic.sort_values([\"vacant\", \"account\", \"pop_2010\"], \\n                                             ascending=(False, True, True))\\n\\n# Print the top few rows of sorted_pop_vac_lic\\nprint(sorted_pop_vac_lic.head())'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Merge land_use and census and merge result with licenses including suffixes\n",
    "land_cen_lic = land_use.merge(census, on='ward') \\\n",
    "                    .merge(licenses, on='ward', suffixes=('_cen','_lic'))\n",
    "\n",
    "# Group by ward, pop_2010, and vacant, then count the # of accounts\n",
    "pop_vac_lic = land_cen_lic.groupby(['ward','pop_2010','vacant'], \n",
    "                                   as_index=False).agg({'account':'count'})\n",
    "\n",
    "# Sort pop_vac_lic and print the results\n",
    "sorted_pop_vac_lic = pop_vac_lic.sort_values([\"vacant\", \"account\", \"pop_2010\"], \n",
    "                                             ascending=(False, True, True))\n",
    "\n",
    "# Print the top few rows of sorted_pop_vac_lic\n",
    "print(sorted_pop_vac_lic.head())'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de32ae7",
   "metadata": {},
   "source": [
    "# 2. Merging Table with Different Join Types \n",
    "\n",
    "    Merge with left join\n",
    "    \n",
    "    movies_tagline = movies.merge(taglines, on = \"id\", how = \"left\")\n",
    "    print(movies_tagline.head())\n",
    "    print(movies_tagline.shape) \n",
    "    \n",
    "    IMPORTANT: LEFT JOIN RETURNS SAME NUMBER OF ROWS AS THE LEFT TABLE\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e581c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ed65e3c",
   "metadata": {},
   "source": [
    "#### 2.1 Counting missing rows with left join\n",
    "\n",
    "The Movie Database is supported by volunteers going out into the world, collecting data, and entering it into the database. This includes financial data, such as movie budget and revenue. If you wanted to know which movies are still missing data, you could use a left join to identify them. Practice using a left join by merging the movies table and the financials table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "253e33f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n# Merge the movies table with the financials table with a left join\\nmovies_financials = movies.merge(financials, on='id', how='left')\\n\\n# Count the number of rows in the budget column that are missing\\nnumber_of_missing_fin = movies_financials['budget'].isnull().sum()\\n\\n# Print the number of movies missing financials\\nprint(number_of_missing_fin)\\n\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "# Merge the movies table with the financials table with a left join\n",
    "movies_financials = movies.merge(financials, on='id', how='left')\n",
    "\n",
    "# Count the number of rows in the budget column that are missing\n",
    "number_of_missing_fin = movies_financials['budget'].isnull().sum()\n",
    "\n",
    "# Print the number of movies missing financials\n",
    "print(number_of_missing_fin)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59af9c0",
   "metadata": {},
   "source": [
    "You used a left join to find out which rows in the financials table were missing data. When performing a left join, the .merge() method returns a row full of null values for columns in the right table if the key column does not have a matching value in both tables. We see that there are at least 1,500 rows missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38acd62c",
   "metadata": {},
   "source": [
    "If your goal is to enhance or enrich a dataset, then you do not want to lose any of your original data. A left join will do that by returning all of the rows of your left table, while using an inner join may result in lost data if it does not exist in both tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7f4d49",
   "metadata": {},
   "source": [
    "#### 2.1.1 How many rows with a left join?\n",
    "\n",
    "A left join will return all of the rows from the left table. If those rows in the left table match multiple rows in the right table, then all of those rows will be returned. Therefore, the returned rows must be equal to if not greater than the left table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166a2059",
   "metadata": {},
   "source": [
    "### 2.2 Other joins\n",
    "\n",
    "Right Join\n",
    "\n",
    "    Looking at data\n",
    "\n",
    "        movie_to_genres = pd.read_csv(\"tmdb_movie_to_genres.csv')\n",
    "        tv_genre = movie_to_genres[movie_to_genres[\"genre\"] == \"TV Movie\"]\n",
    "        print(tv_genre)\n",
    "\n",
    "    Data to Merge\n",
    "\n",
    "        tv_movies = movies.merge(tv_genre, how = \"right\", left_on = 'id', right_on = 'movie_id')\n",
    "        print(tv_movies.head())\n",
    "\n",
    "Outer Join - An outer join will return all of the rows from both tables regardless if there is a match between the tables.\n",
    "\n",
    "\n",
    "    family_comedy = family.merge(comedy, on \"movie_id\", how =\"outer\", suffixes = [\"_fam\", \"_com\n",
    "    print(family_comedy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd2b62b",
   "metadata": {},
   "source": [
    "#### 2.2.1 Right join to find unique movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb228ab3",
   "metadata": {},
   "source": [
    "Most of the recent big-budget science fiction movies can also be classified as action movies. You are given a table of science fiction movies called scifi_movies and another table of action movies called action_movies. \n",
    "\n",
    "Your goal is to find which movies are considered only science fiction movies. Once you have this table, you can merge the movies table in to see the movie names. Since this exercise is related to science fiction movies, use a right join as your superhero power to solve this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80cc7282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# Merge action_movies to the scifi_movies with right join\\naction_scifi = action_movies.merge(scifi_movies, on=\\'movie_id\\', how=\\'right\\',\\n                                   suffixes=(\\'_act\\',\\'_sci\\'))\\n\\n# From action_scifi, select only the rows where the genre_act column is null\\nscifi_only = action_scifi[action_scifi[\\'genre_act\\'].isnull()]\\n\\n# Merge the movies and scifi_only tables with an inner join\\nmovies_and_scifi_only = movies.merge(scifi_only, how = \"inner\", left_on = \"id\", right_on = \"movie_id\")\\n\\n# Print the first few rows and shape of movies_and_scifi_only\\nprint(movies_and_scifi_only.head())\\nprint(movies_and_scifi_only.shape)\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "# Merge action_movies to the scifi_movies with right join\n",
    "action_scifi = action_movies.merge(scifi_movies, on='movie_id', how='right',\n",
    "                                   suffixes=('_act','_sci'))\n",
    "\n",
    "# From action_scifi, select only the rows where the genre_act column is null\n",
    "scifi_only = action_scifi[action_scifi['genre_act'].isnull()]\n",
    "\n",
    "# Merge the movies and scifi_only tables with an inner join\n",
    "movies_and_scifi_only = movies.merge(scifi_only, how = \"inner\", left_on = \"id\", right_on = \"movie_id\")\n",
    "\n",
    "# Print the first few rows and shape of movies_and_scifi_only\n",
    "print(movies_and_scifi_only.head())\n",
    "print(movies_and_scifi_only.shape)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90313e30",
   "metadata": {},
   "source": [
    "#### 2.2.2 Popular genres with right join\n",
    "\n",
    "What are the genres of the most popular movies? To answer this question, you need to merge data from the movies and movie_to_genres tables. In a table called pop_movies, the top 10 most popular movies in the movies table have been selected. To ensure that you are analyzing all of the popular movies, merge it with the movie_to_genres table using a right join. \n",
    "\n",
    "To complete your analysis, count the number of different genres. Also, the two tables can be merged by the movie ID. However, in pop_movies that column is called id, and in movies_to_genres it's called movie_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "114160ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# Use right join to merge the movie_to_genres and pop_movies tables\\ngenres_movies = movie_to_genres.merge(pop_movies, how=\\'right\\', \\n                                      left_on = \"movie_id\", \\n                                      right_on = \\'id\\')\\n\\n# Count the number of genres\\ngenre_count = genres_movies.groupby(\\'genre\\').agg({\\'id\\':\\'count\\'})\\n\\n# Plot a bar chart of the genre_count\\ngenre_count.plot(kind=\\'bar\\')\\nplt.show()\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "# Use right join to merge the movie_to_genres and pop_movies tables\n",
    "genres_movies = movie_to_genres.merge(pop_movies, how='right', \n",
    "                                      left_on = \"movie_id\", \n",
    "                                      right_on = 'id')\n",
    "\n",
    "# Count the number of genres\n",
    "genre_count = genres_movies.groupby('genre').agg({'id':'count'})\n",
    "\n",
    "# Plot a bar chart of the genre_count\n",
    "genre_count.plot(kind='bar')\n",
    "plt.show()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c796254",
   "metadata": {},
   "source": [
    "#### 2.2.3 Popular genres with right join\n",
    "\n",
    "One cool aspect of using an outer join is that, because it returns all rows from both merged tables and null where they do not match, you can use it to find rows that do not have a match in the other table. \n",
    "\n",
    "To try for yourself, you have been given two tables with a list of actors from two popular movies: Iron Man 1 and Iron Man 2. Most of the actors played in both movies. Use an outer join to find actors who did not act in both movies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f364bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# Merge iron_1_actors to iron_2_actors on id with outer join using suffixes\\niron_1_and_2 = iron_1_actors.merge(iron_2_actors,\\n                                     how = \"outer\",\\n                                     on = \"id\",\\n                                     suffixes=(\"_1\", \"_2\"))\\nprint(iron_1_and_2)\\n# Create an index that returns true if name_1 or name_2 are null\\nm = ((iron_1_and_2[\\'name_1\\'].isnull()) | \\n     (iron_1_and_2[\\'name_2\\'].isnull()))\\n\\n# Print the first few rows of iron_1_and_2\\nprint(iron_1_and_2[m].head())\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "# Merge iron_1_actors to iron_2_actors on id with outer join using suffixes\n",
    "iron_1_and_2 = iron_1_actors.merge(iron_2_actors,\n",
    "                                     how = \"outer\",\n",
    "                                     on = \"id\",\n",
    "                                     suffixes=(\"_1\", \"_2\"))\n",
    "print(iron_1_and_2)\n",
    "# Create an index that returns true if name_1 or name_2 are null\n",
    "m = ((iron_1_and_2['name_1'].isnull()) | \n",
    "     (iron_1_and_2['name_2'].isnull()))\n",
    "\n",
    "# Print the first few rows of iron_1_and_2\n",
    "print(iron_1_and_2[m].head())\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546dd092",
   "metadata": {},
   "source": [
    "### 2.3 Merging a table to itself\n",
    "\n",
    "\n",
    "    original_sequels = sequels.merge(sequels, left_on = \"sequel\", right_on =\"id\", suffixes= (\"_org\", \"_seq\"))\n",
    "    \n",
    "    Format results \n",
    "    \n",
    "        print(original_sequels[,[\"title_org\", \"title_seq\"]].head()) \n",
    "\n",
    "When to merge at table to itself:\n",
    "\n",
    "1. Hierarchical Relationships (ex. employee, manager)\n",
    "2. Sequential relationships\n",
    "3. Graph data (network of friends?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e863041c",
   "metadata": {},
   "source": [
    "#### 2.3.1 Self join\n",
    "\n",
    "Merging a table to itself can be useful when you want to compare values in a column to other values in the same column. \n",
    "\n",
    "In this exercise, you will practice this by creating a table that for each movie will list the movie director and a member of the crew on one row. You have been given a table called crews, which has columns id, job, and name. First, merge the table to itself using the movie ID. This merge will give you a larger table where for each movie, every job is matched against each other. Then select only those rows with a director in the left table, and avoid having a row where the director's job is listed in both the left and right tables. This filtering will remove job combinations that aren't with the director."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2030cbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n# Merge the crews table to itself\\ncrews_self_merged = crews.merge(crews, on='id', how='inner',\\n                                suffixes=('_dir','_crew'))\\n\\n# Create a boolean index to select the appropriate rows\\nboolean_filter = ((crews_self_merged['job_dir'] == 'Director') & \\n                  (crews_self_merged['job_crew'] != 'Director'))\\ndirect_crews = crews_self_merged[boolean_filter]\\n\\n# Print the first few rows of direct_crews\\nprint(direct_crews.head())\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "# Merge the crews table to itself\n",
    "crews_self_merged = crews.merge(crews, on='id', how='inner',\n",
    "                                suffixes=('_dir','_crew'))\n",
    "\n",
    "# Create a boolean index to select the appropriate rows\n",
    "boolean_filter = ((crews_self_merged['job_dir'] == 'Director') & \n",
    "                  (crews_self_merged['job_crew'] != 'Director'))\n",
    "direct_crews = crews_self_merged[boolean_filter]\n",
    "\n",
    "# Print the first few rows of direct_crews\n",
    "print(direct_crews.head())\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47bba55",
   "metadata": {},
   "source": [
    "Great job! By merging the table to itself, you compared the value of the director from the jobs column to other values from the jobs column. With the output, you can quickly see different movie directors and the people they worked with in the same movie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d895480",
   "metadata": {},
   "source": [
    "#### 2.4 Merging on indexes\n",
    "\n",
    "    movies = pd.read_csv(\"tmdb_movies.csv\", index_col = [\"id\"])\n",
    "    print(movies.head())\n",
    "    \n",
    "    Multiindex datasets \n",
    "    \n",
    "    samuel = pd.read_csv(\"samuel.csv\", index_col = [\"movie_id\", \"cast_id\"]\n",
    "    casts = pd.read_csv(\"casts.csv\", index_col = [\"movie_id\", \"cast_id\"]\n",
    "    \n",
    "    samuel_casts = samuel,nerge(casts, on = [\"movie_id\", \"cast_id\"])\n",
    "    \n",
    "     If the index level names are different between the two tables that we want to merge, then we can use the left_on and right_on arguments of the merge method\n",
    "     \n",
    "         movie_genres ] movies.merge(\"movie_to_genres\", left_on = \"id\", left_index = True, right_on = \"movie_index\", right_index = True)\n",
    "         \n",
    "          Whenever we are using the left_on or right_on arguments with an index, we need to set the respective left_index and right_index arguments to True. The left_index and right_index tell the merge method to use the separate indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "896ff7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Merge to the movies table the ratings table on the index\\nmovies_ratings = movies.merge(ratings, on = [\"id\"])\\n\\nprint(movies.head())\\nprint(ratings.head())\\n\\n# Print the first few rows of movies_ratings\\nprint(movies_ratings.head())'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Merge to the movies table the ratings table on the index\n",
    "movies_ratings = movies.merge(ratings, on = [\"id\"])\n",
    "\n",
    "print(movies.head())\n",
    "print(ratings.head())\n",
    "\n",
    "# Print the first few rows of movies_ratings\n",
    "print(movies_ratings.head())'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b2c1a6",
   "metadata": {},
   "source": [
    "#### 2.4.1 Do sequels earn more?\n",
    "\n",
    "In this exercise, you'll find out which movie sequels earned the most compared to the original movie. To answer this question, you will merge a modified version of the sequels and financials tables where their index is the movie ID. You will need to choose a merge type that will return all of the rows from the sequels table and not all the rows of financials table need to be included in the result. From there, you will join the resulting table to itself so that you can compare the revenue values of the original movie to the sequel. Next, you will calculate the difference between the two revenues and sort the resulting dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d2cefb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n# Merge sequels and financials on index id\\nsequels_fin = sequels.merge(financials, on='id', how='left')\\n\\n# Self merge with suffixes as inner join with left on sequel and right on id\\norig_seq = sequels_fin.merge(sequels_fin, how='inner', left_on='sequel', \\n                             right_on='id', right_index=True,\\n                             suffixes=('_org','_seq'))\\n\\n# Add calculation to subtract revenue_org from revenue_seq \\norig_seq['diff'] = orig_seq['revenue_seq'] - orig_seq['revenue_org']\\n\\n# Select the title_org, title_seq, and diff \\ntitles_diff = orig_seq[['title_org','title_seq','diff']]\\n\\n# Print the first rows of the sorted titles_diff\\nprint(titles_diff.sort_values('diff', ascending = False).head())\\n\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "# Merge sequels and financials on index id\n",
    "sequels_fin = sequels.merge(financials, on='id', how='left')\n",
    "\n",
    "# Self merge with suffixes as inner join with left on sequel and right on id\n",
    "orig_seq = sequels_fin.merge(sequels_fin, how='inner', left_on='sequel', \n",
    "                             right_on='id', right_index=True,\n",
    "                             suffixes=('_org','_seq'))\n",
    "\n",
    "# Add calculation to subtract revenue_org from revenue_seq \n",
    "orig_seq['diff'] = orig_seq['revenue_seq'] - orig_seq['revenue_org']\n",
    "\n",
    "# Select the title_org, title_seq, and diff \n",
    "titles_diff = orig_seq[['title_org','title_seq','diff']]\n",
    "\n",
    "# Print the first rows of the sorted titles_diff\n",
    "print(titles_diff.sort_values('diff', ascending = False).head())\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c48f71",
   "metadata": {},
   "source": [
    "To complete this exercise, you needed to merge tables on their index and merge another table to itself. After the calculations were added and sub-select specific columns, the data was sorted. You found out that Jurassic World had one of the highest of all, improvement in revenue compared to the original movie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e589a0c5",
   "metadata": {},
   "source": [
    "## 3. Advanced Merging and Concatenating \n",
    "\n",
    "    Filtering Joins \n",
    "    \n",
    "        Mutating vs. Filtering\n",
    "        \n",
    "        Mutating: Combines data from two tables based on matching obs \n",
    "        Filtering: Filter observations from table based on whether or not they match an obs \n",
    "\n",
    "    Semijoin\n",
    "    \n",
    "        * intersection, similar to inner join \n",
    "        * onlycolumns from the left table and not the right\n",
    "        * No duplicates \n",
    "    \n",
    "        Step 1: \n",
    "        \n",
    "            genres_tracks = genres.merge(top_tracks, on = \"gid\")\n",
    "            \n",
    "        Step 2 \n",
    "            \n",
    "            genres[\"gid\"].isin(genres_tracks[\"gid\"])\n",
    "        \n",
    "        Step 3: \n",
    "            genres_tracks = genres.merge(top_tracks, on = \"gid\")\n",
    "            top_genres = genres[genres[\"gid\"].isin(genres_tracks[\"gid\"])]\n",
    "\n",
    "     Antijoin \n",
    "         \n",
    "         * returns the left table, excluding the intersection \n",
    "         * returns only columns from the left table \n",
    "         \n",
    "         \n",
    "        Step 1: \n",
    "        \n",
    "            genres_tracks = genres.merge(top_tracks, on = \"gid\", how = \"left\", indicator = True)\n",
    "            \n",
    "            With indicator set to True, the merge method adds a column called \"_merge\" to the output. This column tells the source of each row. For example, the first four rows found a match in both tables, whereas the last can only be found in the left table.\n",
    "            \n",
    "        Step 2 \n",
    "            \n",
    "           gid_list =  genres_tracks.loc[genres_tracks[\"_merge\"] == \"left_only\", \"gid\"]\n",
    "        \n",
    "        Step 3: \n",
    "        \n",
    "            genres_tracks = genres.merge(top_tracks, on = \"gid\", how = \"left\", indicator = True)\n",
    "            gid_list =  genres_tracks.loc[genres_tracks[\"_merge\"] == \"left_only\", \"gid\"]\n",
    "            non_top_genres = genres[genres[\"gid\"].isin(gid_list)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218e3af4",
   "metadata": {},
   "source": [
    "#### 3.1 Performing an anti join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "980670bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Merge employees and top_cust\\nempl_cust = employees.merge(top_cust, on=\\'srid\\', \\n                                 how=\\'left\\', indicator=True)\\n\\n# Select the srid column where _merge is left_only\\nsrid_list = empl_cust.loc[empl_cust[\\'_merge\\'] == \\'left_only\\', \\'srid\\']\\n\\n# Get employees not working with top customers\\nprint(employees[employees[\"srid\"].isin(srid_list)])'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Merge employees and top_cust\n",
    "empl_cust = employees.merge(top_cust, on='srid', \n",
    "                                 how='left', indicator=True)\n",
    "\n",
    "# Select the srid column where _merge is left_only\n",
    "srid_list = empl_cust.loc[empl_cust['_merge'] == 'left_only', 'srid']\n",
    "\n",
    "# Get employees not working with top customers\n",
    "print(employees[employees[\"srid\"].isin(srid_list)])'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787c7cd3",
   "metadata": {},
   "source": [
    "You performed an anti join by first merging the tables with a left join, selecting the ID of those employees who did not support a top customer, and then subsetting the original employee's table. From that, we can see that there are five employees not supporting top customers. Anti joins are a powerful tool to filter a main table (i.e. employees) by another (i.e. customers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c3c10c",
   "metadata": {},
   "source": [
    "#### 3.2 Performing a semi join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8f5e3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Merge the non_mus_tck and top_invoices tables on tid\\ntracks_invoices = non_mus_tcks.merge(top_invoices, how = \"inner\", on =\"tid\")\\n\\n# Use .isin() to subset non_mus_tcks to rows with tid in tracks_invoices\\ntop_tracks = non_mus_tcks[non_mus_tcks[\\'tid\\'].isin(tracks_invoices[\\'tid\\'])]\\n\\n# Group the top_tracks by gid and count the tid rows\\ncnt_by_gid = top_tracks.groupby([\\'gid\\'], as_index= False).agg({\\'tid\\':\\'count\\'})\\n\\n# Merge the genres table to cnt_by_gid on gid and print\\nprint(cnt_by_gid.merge(genres, on =\"gid\"))'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Merge the non_mus_tck and top_invoices tables on tid\n",
    "tracks_invoices = non_mus_tcks.merge(top_invoices, how = \"inner\", on =\"tid\")\n",
    "\n",
    "# Use .isin() to subset non_mus_tcks to rows with tid in tracks_invoices\n",
    "top_tracks = non_mus_tcks[non_mus_tcks['tid'].isin(tracks_invoices['tid'])]\n",
    "\n",
    "# Group the top_tracks by gid and count the tid rows\n",
    "cnt_by_gid = top_tracks.groupby(['gid'], as_index= False).agg({'tid':'count'})\n",
    "\n",
    "# Merge the genres table to cnt_by_gid on gid and print\n",
    "print(cnt_by_gid.merge(genres, on =\"gid\"))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3aff91",
   "metadata": {},
   "source": [
    "In this exercise, you replicated a semi join to filter the table of tracks by the table of invoice items to find the top revenue non-musical tracks. With some additional data manipulation, you discovered that 'TV-shows' is the non-musical genre that has the most top revenue-generating tracks. Now that you've done both semi- and anti joins, it's time to move to the next topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d78ed",
   "metadata": {},
   "source": [
    "#### 3.3 Concatenate DataFrames together vertically\n",
    "\n",
    "    pandas .concat() method can concatenate both vertically and horizontally \n",
    "        axis = 0, vertical \n",
    "        \n",
    "    Basic concatenation\n",
    "        1. 3 diff tables\n",
    "        2. Same column names\n",
    "        \n",
    "        pd.concat([inv_jan, inv_feb, inv_mar])\n",
    "        pd.concat([inv_jan, inv_feb, inv_mar], ignore_index = True)\n",
    "        pd.concat([inv_jan, inv_feb, inv_mar], ignore_index = False, keys = [\"jan\", \"feb\", \"mar\"])\n",
    "        \n",
    "        \n",
    "    Concatenate with different column names \n",
    "    \n",
    "        pd.concat([inv_jan, inv_feb], sort = True)\n",
    "        pd.concat([inv_jan, inv_feb], join = 'inner')\n",
    "    \n",
    "    Using .append method\n",
    "        Simplified version of the .concat method\n",
    "        Supports: ignore_index, and sort\n",
    "        Does not support: keys and join \n",
    "            Always join = outer\n",
    "            \n",
    "    Append the tables \n",
    "    \n",
    "        inv_jan.append([inv_feb, inv_mar], ignore_index = True, sort = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef25fba",
   "metadata": {},
   "source": [
    "#### 3.3.1 Concatenation basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ab5b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Concatenate the tracks\n",
    "tracks_from_albums = pd.concat([tracks_master, tracks_ride, tracks_st],\n",
    "                               sort=True)\n",
    "print(tracks_from_albums)\n",
    "\n",
    "# Concatenate the tracks so the index goes from 0 to n-1\n",
    "tracks_from_albums = pd.concat([tracks_master, tracks_ride, tracks_st],\n",
    "                               ignore_index = True,\n",
    "                               sort=True)\n",
    "print(tracks_from_albums)\n",
    "\n",
    "# Concatenate the tracks, show only columns names that are in all tables\n",
    "tracks_from_albums = pd.concat([tracks_master, tracks_ride, tracks_st],\n",
    "                               join = \"inner\",\n",
    "                               sort=True)\n",
    "print(tracks_from_albums)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f115be06",
   "metadata": {},
   "source": [
    "#### 3.3.2 Concatenation with keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d5b002",
   "metadata": {},
   "source": [
    "The leadership of the music streaming company has come to you and asked you for assistance in analyzing sales for a recent business quarter. They would like to know which month in the quarter saw the highest average invoice total. You have been given three tables with invoice data named inv_jul, inv_aug, and inv_sep. Concatenate these tables into one to create a graph of the average monthly invoice total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "046e1c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Concatenate the tables and add keys\\ninv_jul_thr_sep = pd.concat([inv_jul, inv_aug,inv_sep], \\n                            keys=[\"7Jul\", \"8Aug\", \"9Sep\"])\\n\\n# Group the invoices by the index keys and find avg of the total column\\navg_inv_by_month = inv_jul_thr_sep.groupby(level=0).agg({\\'total\\': \\'mean\\'})\\n\\n# Bar plot of avg_inv_by_month\\navg_inv_by_month.plot(kind= \"bar\")\\nplt.show()'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Concatenate the tables and add keys\n",
    "inv_jul_thr_sep = pd.concat([inv_jul, inv_aug,inv_sep], \n",
    "                            keys=[\"7Jul\", \"8Aug\", \"9Sep\"])\n",
    "\n",
    "# Group the invoices by the index keys and find avg of the total column\n",
    "avg_inv_by_month = inv_jul_thr_sep.groupby(level=0).agg({'total': 'mean'})\n",
    "\n",
    "# Bar plot of avg_inv_by_month\n",
    "avg_inv_by_month.plot(kind= \"bar\")\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f996008d",
   "metadata": {},
   "source": [
    "There are many ways to write code for this task. However, concatenating the tables with a key provides a hierarchical index that can be used for grouping. Once grouped, you can average the groups and create plots. You were able to find out that September had the highest average invoice total."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b4c314",
   "metadata": {},
   "source": [
    "#### 3.3.3 Using the append method\n",
    "\n",
    "The .concat() method is excellent when you need a lot of control over how concatenation is performed. However, if you do not need as much control, then the .append() method is another option. You'll try this method out by appending the track lists together from different Metallica albums. From there, you will merge it with the invoice_items table to determine which track sold the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5c42159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Use the .append() method to combine the tracks tables\\nmetallica_tracks = tracks_ride.append([tracks_master, tracks_st], sort=False)\\n\\n# Merge metallica_tracks and invoice_items\\ntracks_invoices = metallica_tracks.merge(invoice_items, on='tid')\\n\\n# For each tid and name sum the quantity sold\\ntracks_sold = tracks_invoices.groupby(['tid','name']).agg({'quantity':'sum'})\\n\\n# Sort in decending order by quantity and print the results\\nprint(tracks_sold.sort_values(['quantity'], ascending=False))\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Use the .append() method to combine the tracks tables\n",
    "metallica_tracks = tracks_ride.append([tracks_master, tracks_st], sort=False)\n",
    "\n",
    "# Merge metallica_tracks and invoice_items\n",
    "tracks_invoices = metallica_tracks.merge(invoice_items, on='tid')\n",
    "\n",
    "# For each tid and name sum the quantity sold\n",
    "tracks_sold = tracks_invoices.groupby(['tid','name']).agg({'quantity':'sum'})\n",
    "\n",
    "# Sort in decending order by quantity and print the results\n",
    "print(tracks_sold.sort_values(['quantity'], ascending=False))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbb878f",
   "metadata": {},
   "source": [
    "### 3.4 Verifying Integrity\n",
    "\n",
    "    Merging issue\n",
    "        Unintentional one-to-many relationships\n",
    "        Unintentional many-to-many relationships\n",
    "        \n",
    "    Concatenating issue\n",
    "        Duplicate records possibly unintentionally introduced\n",
    "        \n",
    "        \n",
    "    Validating merges\n",
    "        .merge(validate = None): \n",
    "            Check if merge is of specified type\n",
    "                'one_to_one'\n",
    "                'one_to_many'\n",
    "                'many_to_one'\n",
    "                'many_to_many'\n",
    "                \n",
    "    Verifying concatenations\n",
    "    \n",
    "        pd.concat(verify_integrity = False) \n",
    "\n",
    "            Check whether the new concatenated index contains duplicates\n",
    "            Default value is False  \n",
    "\n",
    "    Why verify integrity and what to do: \n",
    "    \n",
    "        Why? \n",
    "\n",
    "            Real world data is often NOT clean\n",
    "\n",
    "        What to do?\n",
    "            Fix incorrect data\n",
    "            Drop duplicate rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4573ce5",
   "metadata": {},
   "source": [
    "#### 3. 4.1 Concatenate and merge to find common songs\n",
    "\n",
    "The senior leadership of the streaming service is requesting your help again. You are given the historical files for a popular playlist in the classical music genre in 2018 and 2019. Additionally, you are given a similar set of files for the most popular pop music genre playlist on the streaming service in 2018 and 2019. Your goal is to concatenate the respective files to make a large classical playlist table and overall popular music table. Then filter the classical music table using a semi join to return only the most popular classical music tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a4ad5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Concatenate the classic tables vertically\\nclassic_18_19 = pd.concat([classic_18, classic_19], ignore_index=True)\\n\\n# Concatenate the pop tables vertically\\npop_18_19 = pd.concat([pop_18, pop_19], ignore_index=True)\\n\\n# Merge classic_18_19 with pop_18_19\\nclassic_pop = classic_18_19.merge(pop_18_19, on = \"tid\", how = \"inner\")\\n\\n# Using .isin(), filter classic_18_19 rows where tid is in classic_pop\\npopular_classic = classic_18_19[classic_18_19[\"tid\"].isin(classic_pop[\"tid\"])]\\n\\n# Print popular chart\\nprint(popular_classic)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Concatenate the classic tables vertically\n",
    "classic_18_19 = pd.concat([classic_18, classic_19], ignore_index=True)\n",
    "\n",
    "# Concatenate the pop tables vertically\n",
    "pop_18_19 = pd.concat([pop_18, pop_19], ignore_index=True)\n",
    "\n",
    "# Merge classic_18_19 with pop_18_19\n",
    "classic_pop = classic_18_19.merge(pop_18_19, on = \"tid\", how = \"inner\")\n",
    "\n",
    "# Using .isin(), filter classic_18_19 rows where tid is in classic_pop\n",
    "popular_classic = classic_18_19[classic_18_19[\"tid\"].isin(classic_pop[\"tid\"])]\n",
    "\n",
    "# Print popular chart\n",
    "print(popular_classic)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3960a518",
   "metadata": {},
   "source": [
    "## 4. Merging Ordered and Time-Series Data\n",
    "\n",
    "apply pandas' specialized methods for merging time-series and ordered data together with real-world financial and economic data from the city of Chicago. Youâ€™ll also learn how to query resulting tables using a SQL-style format, and unpivot data using the melt method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26522d4e",
   "metadata": {},
   "source": [
    "Method comparison \n",
    "\n",
    "    .merge () \n",
    "    \n",
    "        Columns to join on : on, left_on, right_on \n",
    "        \n",
    "        Type of join: how (left, right, inner, outer)\n",
    "        Default: inner    \n",
    "    \n",
    "    merge_ordered() \n",
    "    \n",
    "        Columns to join on : on, left_on, right_on \n",
    "        \n",
    "        Type of join: how (left, right, inner, outer)\n",
    "        Default: outer\n",
    "        \n",
    "        pd.merge_ordered(df1, df2)\n",
    "   \n",
    "    Merging stock data\n",
    "    \n",
    "        import pandas as pd \n",
    "        pd.merge_ordered(aapl, mcd, on = \"date\", suffixes = [\"_aaple\", \"_mcd\"])\n",
    "        \n",
    "        Forward fill \n",
    "        \n",
    "        pd.merge_ordered(aapl, mcd, on = \"date\", suffixes = [\"_aaple\", \"_mcd\"], fill_method = 'ffill)\n",
    "\n",
    "    When to use merge_ordered()?\n",
    "       Ordered data/time series\n",
    "       Filling in missing values "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
